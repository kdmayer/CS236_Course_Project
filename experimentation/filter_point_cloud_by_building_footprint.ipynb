{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pylas\n",
    "import laspy\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import shapely\n",
    "import os\n",
    "# Test run with SP3176_P_11321_20171123_20171123.las"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use LAStools to convert from Laz to Las\n",
    "# See: https://community.rockrobotic.com/t/running-laszip-to-compress-your-las-files/154\n",
    "# Look into lasclip: https://lastools.github.io/download/lasclip_README.txt\n",
    "laz_dir = \"/Users/kevin/cs236g/P_11321_11322\"\n",
    "\n",
    "for laz_file_name in os.listdir(laz_dir):\n",
    "    \n",
    "    if laz_file_name.endswith(\".laz\"):\n",
    "        \n",
    "        laz_fname = laz_file_name\n",
    "        las_fname = laz_file_name[:-4] + \".las\"\n",
    "\n",
    "        !/Users/kevin/CS236G/LAStools-master/bin/laszip -i /Users/kevin/cs236g/P_11321_11322/{laz_fname} -o /Users/kevin/cs236g/LAS/{las_fname}   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def laz_to_las(input_laz_path, output_las_path):\n",
    "    \n",
    "    las = pylas.read(input_laz_path)    \n",
    "    las = pylas.convert(las)    \n",
    "    las.write(output_las_path)\n",
    "    print(f\"Save LAS file at: {output_las_path}\")\n",
    "    return output_las_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "las_no = 'SP3278'\n",
    "las = laspy.read('/Users/kevin/cs236g/' + las_no + '_P_11321_20171123_20171123.las')\n",
    "las"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert LAS to numpy array (X=raw integer value x=scaled float value)\n",
    "lidar_points = np.array((las.x,las.y,las.z,las.intensity,\n",
    "               las.raw_classification,las.scan_angle_rank)).transpose()\n",
    "lidar_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Transform to pandas DataFrame\n",
    "lidar_df = pd.DataFrame(lidar_points)\n",
    "lidar_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10000000\n",
    "lidar_subset = lidar_df.sample(n=1000, random_state=1)\n",
    "lidar_subset = lidar_subset.reset_index(drop=True)\n",
    "display(lidar_subset)\n",
    "print(lidar_subset[2].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform to geopandas GeoDataFrame\n",
    "# Original CRS is EPSG:27700\n",
    "# Transform to EPSG:4326\n",
    "crs = None\n",
    "geometry_3D = [shapely.geometry.Point(xyz) for xyz in zip(lidar_subset[0], lidar_subset[1], lidar_subset[2])]\n",
    "lidar_3D_gdf = gpd.GeoDataFrame(geometry_3D, crs=crs, geometry=geometry_3D)\n",
    "lidar_3D_gdf.crs = {'init' : 'epsg:27700'} # set correct spatial reference\n",
    "lidar_3D_gdf = lidar_3D_gdf.drop(columns=[0])\n",
    "lidar_3D_gdf = lidar_3D_gdf.to_crs(4326)\n",
    "\n",
    "lidar_3D_gdf['2D_geom'] = [shapely.geometry.Point(xy) for xy in zip(lidar_3D_gdf.geometry.x, lidar_3D_gdf.geometry.y)]\n",
    "lidar_3D_gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lidar_3D_gdf = lidar_3D_gdf.set_geometry('2D_geom')\n",
    "print(f\"Check name of active geometry column: {lidar_3D_gdf.geometry.name}\")\n",
    "print(f\"Check CRS of active geometry column: {lidar_3D_gdf.geometry.crs}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "buidling_footprints = gpd.read_file(\"/Users/kevin/cs236g/coventry_building_footprints.geojson\")\n",
    "buidling_footprints = buidling_footprints.loc[buidling_footprints.geometry.apply(lambda x: isinstance(x, shapely.geometry.polygon.Polygon))]\n",
    "buidling_footprints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The spatial join automatically drops the 2D_geom column\n",
    "points_per_footprint = gpd.sjoin(buidling_footprints, lidar_3D_gdf, how=\"inner\", op='intersects')\n",
    "points_per_footprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "points_per_footprint = points_per_footprint.set_geometry('geometry_right')\n",
    "print(f\"Check name of active geometry column: {points_per_footprint.geometry.name}\")\n",
    "print(f\"Check CRS of active geometry column: {points_per_footprint.geometry.crs}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "points_per_footprint['index_id'] = points_per_footprint.index\n",
    "points_per_footprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "points_per_footprint_dissolved = points_per_footprint.dissolve('index_id')\n",
    "points_per_footprint_dissolved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "points_per_footprint_dissolved = points_per_footprint_dissolved.rename_geometry('points_per_footprint')\n",
    "points_per_footprint_dissolved = points_per_footprint_dissolved.rename(columns={'geometry_left':'footprint_polygon'})\n",
    "points_per_footprint_dissolved = points_per_footprint_dissolved.reset_index(drop=True)\n",
    "points_per_footprint_dissolved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Check name of active geometry column: {points_per_footprint_dissolved.geometry.name}\")\n",
    "print(f\"Check CRS of active geometry column: {points_per_footprint_dissolved.geometry.crs}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "points_per_footprint_dissolved = points_per_footprint_dissolved.loc[points_per_footprint_dissolved.geometry.apply(lambda x: isinstance(x, shapely.geometry.MultiPoint))]\n",
    "points_per_footprint_dissolved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "points_per_footprint_dissolved['num_points'] = points_per_footprint_dissolved.apply(lambda row: len(row.points_per_footprint), axis=1)\n",
    "points_per_footprint_dissolved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert points_per_footprint back to EPSG:27700\n",
    "points_per_footprint_dissolved = points_per_footprint_dissolved.to_crs(27700)\n",
    "points_per_footprint_dissolved = points_per_footprint_dissolved.set_geometry('footprint_polygon')\n",
    "points_per_footprint_dissolved['footprint_polygon'] = points_per_footprint_dissolved['footprint_polygon'].set_crs('epsg:4326', allow_override=True)\n",
    "points_per_footprint_dissolved = points_per_footprint_dissolved.to_crs(27700)\n",
    "points_per_footprint_dissolved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add footprint bounds: minx, miny, maxx, maxy\n",
    "points_per_footprint_dissolved['footprint_bounds'] = points_per_footprint_dissolved['footprint_polygon'].apply(lambda footprint: footprint.bounds)\n",
    "# expand footprint polygon bounds into its own dataframe\n",
    "bounds = points_per_footprint_dissolved['footprint_bounds'].apply(pd.Series)\n",
    "bounds = bounds.rename(columns = {0:'footprint_minx', 1:'footprint_miny', 2:'footprint_maxx', 3:'footprint_maxy'})\n",
    "points_per_footprint_dissolved = pd.concat([points_per_footprint_dissolved, bounds], axis=1)\n",
    "points_per_footprint_dissolved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# determine the footprint polygon bounds for each building \n",
    "# and normalize for each point within the respective object (house) to lie between 0 and 1\n",
    "copy_gdf = points_per_footprint_dissolved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_z(row):\n",
    "    max_z = 0\n",
    "    for elem in list(row.points_per_footprint.geoms):\n",
    "        if elem.z > max_z:\n",
    "            max_z = elem.z\n",
    "    return max_z\n",
    "\n",
    "def min_z(row):\n",
    "    min_z = 1000\n",
    "    for elem in list(row.points_per_footprint.geoms):\n",
    "        if elem.z < min_z:\n",
    "            min_z = elem.z\n",
    "    return min_z\n",
    "\n",
    "def point_to_numpy(row):\n",
    "    point_list = []\n",
    "    for point in list(row.points_per_footprint.geoms):\n",
    "        point_list.append([point.x, point.y, point.z])\n",
    "    return point_list\n",
    "\n",
    "def normalize_points(row):\n",
    "    normalized_points = []\n",
    "    footprint_minx = row['footprint_minx']\n",
    "    footprint_miny = row['footprint_miny']\n",
    "    footprint_maxx = row['footprint_maxx']\n",
    "    footprint_maxy = row['footprint_maxy']\n",
    "    \n",
    "    for point in list(row.unnormalized_points):\n",
    "        normalized_x = (point[0] - footprint_minx) / (footprint_maxx - footprint_minx)\n",
    "        normalized_y = (point[1] - footprint_miny) / (footprint_maxy - footprint_miny)\n",
    "        normalized_z = (point[2] - row.min_z) / ((row.max_z - row.min_z) + 0.0000001)\n",
    "        normalized_points.append([normalized_x, normalized_y, normalized_z]) \n",
    "    normalized_points_np = np.asarray(normalized_points, dtype=np.float32)\n",
    "    return normalized_points_np\n",
    "        \n",
    "copy_gdf['max_z'] = copy_gdf.apply(max_z, axis=1)\n",
    "copy_gdf['min_z'] = copy_gdf.apply(min_z, axis=1)\n",
    "copy_gdf['mean_z'] = copy_gdf.apply(lambda row: (row.max_z + row.min_z)/2, axis=1)\n",
    "copy_gdf['unnormalized_points'] = copy_gdf.apply(point_to_numpy, axis=1)\n",
    "copy_gdf['normalized_points'] = copy_gdf.apply(normalize_points, axis=1)\n",
    "# multipoint to numpy array\n",
    "copy_gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "save_path = '/Users/kevin/cs236g/' + las_no + '_PC_Coventry.pickle'\n",
    "with open(save_path, 'wb') as fp:\n",
    "    pickle.dump(copy_gdf, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
