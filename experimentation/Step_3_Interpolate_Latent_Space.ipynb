{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "101938ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/Users/kevin/Projects/CS236_Course_Project')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87cb4cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objs as go\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from src.model import Generator\n",
    "from src.trainer import Trainer\n",
    "from src.metrics import compute_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eda1973",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 1\n",
    "DEVICE = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "CKPT_PATH = \"/Users/kevin/Projects/CS236_Course_Project/checkpoints/sinkhorn_energy_gaussian_laplacian_2023-12-02_13-49-52/1900.pth\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6a62553",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load point cloud file\n",
    "example_pc_path = \"/Users/kevin/Projects/CS236_Course_Project/mock_data/Test/451927.8000000001_453201.865.npy\"\n",
    "real_point_cloud = torch.from_numpy(np.load(example_pc_path)).unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cb25ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_point_cloud(data: np.ndarray):\n",
    "    # Assuming your data is a NumPy array of shape [1000, 3]\n",
    "    # Create 3D scatter plot\n",
    "    trace = go.Scatter3d(\n",
    "        x=data[:, 0],\n",
    "        y=data[:, 1],\n",
    "        z=data[:, 2],\n",
    "        mode='markers',\n",
    "        marker=dict(\n",
    "            size=3,\n",
    "            color=data[:, 2],  # You can use another column for color\n",
    "            colorscale='Viridis',\n",
    "            opacity=0.8\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Create layout\n",
    "    layout = go.Layout(scene=dict(aspectmode='data'))\n",
    "\n",
    "    # Create figure\n",
    "    fig = go.Figure(data=[trace], layout=layout)\n",
    "\n",
    "    # Show the plot\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f135f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load trained generator model checkpoint \n",
    "\n",
    "# Setup model\n",
    "net_g = Generator()\n",
    "net_g.eval()\n",
    "\n",
    "# Setup trainer\n",
    "trainer = Trainer(net_g=net_g, batch_size=BATCH_SIZE, device=DEVICE)\n",
    "\n",
    "# Load checkpoint\n",
    "trainer.load_checkpoint(CKPT_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26b9f5c9",
   "metadata": {},
   "source": [
    "### TBD what is the correct approach:\n",
    "\n",
    "net_g.decode() adds random noise to the encoded latent point cloud to generate new point cloud. We do this in an attempt to learn a meaningful latent space representation of point clouds. However, during inference time, my hypothesis would be that we do not add random noise and just generate point clouds from the interpolated latents directly (as indicated in the cell below)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0cac8e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example taken from Trainer.test()\n",
    "generated_point_cloud, latent_point_cloud = net_g(real_point_cloud)\n",
    "# generated_point_cloud has shape: torch.Size([1, 500, 3])\n",
    "metrics_original = compute_metrics(generated_point_cloud, real_point_cloud, BATCH_SIZE)\n",
    "generated_point_cloud = generated_point_cloud.squeeze().detach().numpy()\n",
    "\n",
    "print(f\"Original Metrics: {metrics_original}\")\n",
    "visualize_point_cloud(generated_point_cloud)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c725a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# My idea\n",
    "# Wait, net_g.decode() also adds noise to the latent point cloud. So, we should just use the latent point cloud to generate the point cloud.\n",
    "generated_output = net_g.decode(latent_point_cloud, 1, 500, DEVICE)\n",
    "metrics_output = compute_metrics(generated_output, real_point_cloud, BATCH_SIZE)\n",
    "generated_output = generated_output.squeeze().detach().numpy()\n",
    "print(f\"Output Metrics: {metrics_output}\")\n",
    "visualize_point_cloud(generated_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9252db12",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
