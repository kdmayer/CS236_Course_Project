{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "101938ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/Users/kevin/Projects/CS236_Course_Project')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87cb4cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objs as go\n",
    "import plotly as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from src.model import Generator\n",
    "from src.trainer import Trainer\n",
    "from src.metrics import compute_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eda1973",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 1\n",
    "DEVICE = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "CKPT_PATH = \"/Users/kevin/Projects/CS236_Course_Project/checkpoints/sinkhorn_energy_gaussian_laplacian_2023-12-02_14-11-58/100.pth\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6a62553",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load point cloud file\n",
    "real_pc_one = torch.from_numpy(np.load(\"/Users/kevin/Projects/CS236_Course_Project/mock_data/Test/451927.8000000001_453201.865.npy\")).unsqueeze(0)\n",
    "real_pc_two = torch.from_numpy(np.load(\"/Users/kevin/Projects/CS236_Course_Project/mock_data/Test/451996.5849999999_453310.49.npy\")).unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cb25ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_point_cloud(data: np.ndarray):\n",
    "    # Assuming your data is a NumPy array of shape [1000, 3]\n",
    "    # Create 3D scatter plot\n",
    "    trace = go.Scatter3d(\n",
    "        x=data[:, 0],\n",
    "        y=data[:, 1],\n",
    "        z=data[:, 2],\n",
    "        mode='markers',\n",
    "        marker=dict(\n",
    "            size=3,\n",
    "            color=data[:, 2],  # You can use another column for color\n",
    "            colorscale='Viridis',\n",
    "            opacity=0.8\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Create layout\n",
    "    layout = go.Layout(scene=dict(aspectmode='data'))\n",
    "\n",
    "    # Create figure\n",
    "    fig = go.Figure(data=[trace], layout=layout)\n",
    "\n",
    "    # Show the plot\n",
    "    fig.show()\n",
    "    \n",
    "def plot_samples(samples, num=5, rows=2, cols=3):\n",
    "    fig = plt.subplots.make_subplots(\n",
    "        rows=rows,\n",
    "        cols=cols,\n",
    "        specs=[[{\"type\": \"Scatter3d\"} for _ in range(cols)] for _ in range(rows)],\n",
    "    )\n",
    "\n",
    "    for i, sample in enumerate(samples):\n",
    "        fig.add_trace(\n",
    "            plt.graph_objects.Scatter3d(\n",
    "                x=sample[:, 0],\n",
    "                y=sample[:, 2],\n",
    "                z=sample[:, 1],\n",
    "                mode=\"markers\",\n",
    "                marker=dict(size=3, opacity=0.8),\n",
    "            ),\n",
    "            row=i // cols + 1,\n",
    "            col=i % cols + 1,\n",
    "        )\n",
    "    fig.update_layout(showlegend=False)\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f135f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load trained generator model checkpoint \n",
    "\n",
    "# Setup model\n",
    "net_g = Generator()\n",
    "net_g.eval()\n",
    "\n",
    "# Setup trainer\n",
    "trainer = Trainer(net_g=net_g, batch_size=BATCH_SIZE, device=DEVICE)\n",
    "\n",
    "# Load checkpoint\n",
    "trainer.load_checkpoint(CKPT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbbc3c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, z1_one = net_g(real_pc_one)\n",
    "_, z1_two = net_g(real_pc_two)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d156bfeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check shape of z1 vectors\n",
    "z1_one.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d40ac15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vector a is defined as going from z1_one to z1_two\n",
    "a = z1_two.squeeze() - z1_one.squeeze()\n",
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3da953eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_codes = []\n",
    "interpolation_steps = 3\n",
    "\n",
    "for step in range(interpolation_steps+1):\n",
    "    if step == 0:\n",
    "        latent_codes.append(z1_one)\n",
    "    else:\n",
    "        latent_vector = z1_one + (step/interpolation_steps) * a\n",
    "        latent_codes.append(latent_vector)\n",
    "\n",
    "latent_codes.append(z1_two)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31c346db",
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_samples = []\n",
    "\n",
    "for z1 in latent_codes:\n",
    "    \n",
    "    decoded_output = net_g.decode(z1, 1, 500, DEVICE, interpolating=True).squeeze().detach().numpy()\n",
    "    \n",
    "    generated_samples.append(decoded_output)\n",
    "\n",
    "plot_samples(generated_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5af59f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84b8c888",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98199dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "z1_one_output = net_g.decode(z1_one, 1, 500, DEVICE).squeeze().detach().numpy()\n",
    "visualize_point_cloud(z1_one_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c93ec6e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "z1_two_output = net_g.decode(z1_two, 1, 500, DEVICE).squeeze().detach().numpy()\n",
    "visualize_point_cloud(z1_two_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49b236c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe537f6a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5aa247b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3277669",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1613ae06",
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_one = torch.randn(1, 500, 512).to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8891e23d",
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_one = net_g.decoder_network.latent_to_point_cloud(latent_one)\n",
    "generated_one.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26b9f5c9",
   "metadata": {},
   "source": [
    "### TBD what is the correct approach:\n",
    "\n",
    "net_g.decode() adds random noise to the encoded latent point cloud to generate new point cloud. We do this in an attempt to learn a meaningful latent space representation of point clouds. However, during inference time, my hypothesis would be that we do not add random noise and just generate point clouds from the interpolated latents directly (as indicated in the cell below)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0cac8e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example taken from Trainer.test()\n",
    "generated_point_cloud, latent_point_cloud = net_g(real_point_cloud)\n",
    "# generated_point_cloud has shape: torch.Size([1, 500, 3])\n",
    "metrics_original = compute_metrics(generated_point_cloud, real_point_cloud, BATCH_SIZE)\n",
    "generated_point_cloud = generated_point_cloud.squeeze().detach().numpy()\n",
    "\n",
    "print(f\"Original Metrics: {metrics_original}\")\n",
    "visualize_point_cloud(generated_point_cloud)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c725a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# My idea\n",
    "# Wait, net_g.decode() also adds noise to the latent point cloud. So, we should just use the latent point cloud to generate the point cloud.\n",
    "generated_output = net_g.decode(latent_point_cloud, 1, 500, DEVICE)\n",
    "metrics_output = compute_metrics(generated_output, real_point_cloud, BATCH_SIZE)\n",
    "generated_output = generated_output.squeeze().detach().numpy()\n",
    "print(f\"Output Metrics: {metrics_output}\")\n",
    "visualize_point_cloud(generated_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9252db12",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
